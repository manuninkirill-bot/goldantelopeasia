import os, requests, re, time
from bs4 import BeautifulSoup
from PIL import Image
from io import BytesIO

BASE_PATH = "/home/poweramanita/goldantelopeasia/auto_nhatrang"
SOURCE_URL = "https://getmecar.ru/locations/vetnam/"

def slugify(text):
    text = text.lower()
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–π —à—É–º –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    text = re.sub(r'–∏–ª–∏ –∞–Ω–∞–ª–æ–≥.*|–≤ –Ω—è—á–∞–Ω–≥–µ.*|–≤—å–µ—Ç–Ω–∞–º.*|–∞—Ä–µ–Ω–¥–∞.*|–∞–≤—Ç–æ–º–∞—Ç.*', '', text)
    return "".join(re.findall(r'[a-z0-9]', text))

def main():
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://getmecar.ru/"
    }
    
    print(f"üåê –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ GetMeCar...")
    try:
        response = requests.get(SOURCE_URL, headers=headers, timeout=30)
        soup = BeautifulSoup(response.text, 'html.parser')
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}")
        return

    # –ù–∞ GetMeCar —Ñ–æ—Ç–æ –ª–µ–∂–∞—Ç –≤ —ç–ª–µ–º–µ–Ω—Ç–∞—Ö —Å –∫–ª–∞—Å—Å–æ–º 'catalog-item'
    items = soup.find_all('div', class_=re.compile(r'catalog-item|item'))
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(items)} –∫–∞—Ä—Ç–æ—á–µ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.")

    # –°–æ–∑–¥–∞–µ–º –±–∞–∑—É: –Ω–∞–∑–≤–∞–Ω–∏–µ -> —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–æ—Ç–æ
    site_data = []
    for item in items:
        title_tag = item.find(['div', 'a', 'h3'], class_=re.compile(r'title|name'))
        img_tag = item.find('img')
        
        if title_tag and img_tag:
            name = title_tag.get_text(strip=True)
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—É—Ç—å –∫ —Ñ–æ—Ç–æ (–Ω–∞ —Å–∞–π—Ç–µ —á–∞—Å—Ç–æ data-src –¥–ª—è –ª–µ–Ω–∏–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏)
            img_url = img_tag.get('data-src') or img_tag.get('src') or img_tag.get('data-original')
            
            if img_url:
                if not img_url.startswith('http'):
                    img_url = "https://getmecar.ru" + img_url
                site_data.append({'name': name, 'url': img_url})

    # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –ø–∞–ø–∫–∞–º–∏
    folders = [d for d in os.listdir(BASE_PATH) if os.path.isdir(os.path.join(BASE_PATH, d))]
    success = 0

    for folder in folders:
        f_slug = slugify(folder)
        photo_path = os.path.join(BASE_PATH, folder, "photo.jpg")
        
        for car in site_data:
            c_slug = slugify(car['name'])
            # –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –Ω–∞ —Å–∞–π—Ç–µ
            if f_slug in c_slug or c_slug in f_slug:
                print(f"üì∏ –°–∫–∞—á–∏–≤–∞—é –æ—Ä–∏–≥–∏–Ω–∞–ª –¥–ª—è: {folder}")
                try:
                    img_res = requests.get(car['url'], headers=headers, timeout=15)
                    if img_res.status_code == 200:
                        img = Image.open(BytesIO(img_res.content)).convert("RGB")
                        img.save(photo_path, "JPEG", quality=90)
                        success += 1
                        time.sleep(0.5) # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                        break
                except Exception as e:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")

    print(f"\nüèÅ –ì–æ—Ç–æ–≤–æ! –°–∫–∞—á–∞–Ω–æ —Ä–µ–∞–ª—å–Ω—ã—Ö —Ñ–æ—Ç–æ: {success}")

if __name__ == "__main__":
    main()
