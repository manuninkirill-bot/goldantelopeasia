import os, requests, re
from bs4 import BeautifulSoup
from PIL import Image
from io import BytesIO

BASE_PATH = "/home/poweramanita/goldantelopeasia/auto_nhatrang"
SOURCE_URL = "https://getmecar.ru/listing/"

def slugify(text):
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–ª–æ–≤–∞ –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—É—Ç—å (–±—Ä–µ–Ω–¥ –º–æ–¥–µ–ª—å –≥–æ–¥)
    text = re.sub(r'–∏–ª–∏ –∞–Ω–∞–ª–æ–≥.*|–≤ –Ω—è—á–∞–Ω–≥–µ.*|–≤—å–µ—Ç–Ω–∞–º.*', '', text, flags=re.IGNORECASE)
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã –∏ —Ü–∏—Ñ—Ä—ã
    return "".join(re.findall(r'[a-z0-9]', text.lower().replace(' ', '')))

def main():
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
    }
    
    print(f"üåê –ó–∞–≥—Ä—É–∂–∞—é —Å–ø–∏—Å–æ–∫ –∞–≤—Ç–æ —Å {SOURCE_URL}...")
    try:
        response = requests.get(SOURCE_URL, headers=headers, timeout=30)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}")
        return

    # –ù–∞—Ö–æ–¥–∏–º –∫–∞—Ä—Ç–æ—á–∫–∏ –∞–≤—Ç–æ. –ù–∞ GetMeCar —ç—Ç–æ –æ–±—ã—á–Ω–æ –±–ª–æ–∫–∏ —Å –∫–ª–∞—Å—Å–æ–º 'listing-item' –∏–ª–∏ 'card'
    car_data = []
    # –ò—â–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —Å—Å—ã–ª–æ–∫ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
    for card in soup.find_all(['div', 'a'], class_=re.compile(r'item|card|listing')):
        title_tag = card.find(['h3', 'h4', 'div', 'a'], class_=re.compile(r'title|name'))
        img_tag = card.find('img')
        
        if title_tag and img_tag:
            name = title_tag.get_text(strip=True)
            # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            src = img_tag.get('data-src') or img_tag.get('src') or img_tag.get('data-original') or img_tag.get('srcset')
            
            if src:
                # –û—á–∏—Å—Ç–∫–∞ URL, –µ—Å–ª–∏ —Ç–∞–º srcset
                src = src.split(' ')[0]
                if not src.startswith('http'):
                    src = "https://getmecar.ru" + src
                car_data.append({'name': name, 'url': src})

    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ñ–æ—Ç–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(car_data)}")

    if not car_data:
        print("ü§î –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–∞—Ä—Ç–æ—á–∫–∏. –í–æ–∑–º–æ–∂–Ω–æ, –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –≤–µ—Ä—Å—Ç–∫–∞.")
        return

    folders = [d for d in os.listdir(BASE_PATH) if os.path.isdir(os.path.join(BASE_PATH, d))]
    updated = 0

    for folder in folders:
        f_slug = slugify(folder)
        photo_path = os.path.join(BASE_PATH, folder, "photo.jpg")
        
        for car in car_data:
            c_slug = slugify(car['name'])
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π
            if f_slug in c_slug or c_slug in f_slug:
                print(f"üì∏ –û–±–Ω–æ–≤–ª—è—é —Ñ–æ—Ç–æ –¥–ª—è: {folder}")
                try:
                    res = requests.get(car['url'], headers=headers, timeout=15)
                    img = Image.open(BytesIO(res.content)).convert("RGB")
                    img.thumbnail((1000, 1000))
                    img.save(photo_path, "JPEG", quality=80, optimize=True)
                    updated += 1
                    break
                except Exception as e:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {folder}: {e}")
                    continue

    print(f"\nüèÅ –ò—Ç–æ–≥: –†–µ–∞–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ {updated} –ø–∞–ø–æ–∫.")

if __name__ == "__main__":
    main()
